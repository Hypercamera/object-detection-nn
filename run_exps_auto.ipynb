{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cStringIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97a513e6e5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcStringIO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cStringIO'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import json\n",
    "import hashlib\n",
    "import tempfile\n",
    "import keras.optimizers\n",
    "import pickle\n",
    "import datetime\n",
    "import cv2\n",
    "import math\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape\n",
    "import ast\n",
    "import h5py\n",
    "from keras.utils import np_utils\n",
    "from itertools import tee\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run util.py\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_PER_SEC = 10 # frame rat e we decode the video\n",
    "FULL_RESOL = (720, 1280) # default 720p\n",
    "\n",
    "def str2ilst(s):\n",
    "    return [int(x) for x in s.split(',')]\n",
    "\n",
    "def add_json_file(key, val, fname):\n",
    "    res = {}\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname) as f:\n",
    "            res = json.load(f)\n",
    "    res[key] = val\n",
    "    with open(fname, 'w+') as out_f:\n",
    "        json.dump(res, out_f)\n",
    "\n",
    "def already_saved(key, fname):\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname) as f:\n",
    "            res = json.load(f)\n",
    "            if key in res: return True\n",
    "    return False\n",
    "\n",
    "def get_score_fname(cur_cfg):\n",
    "    scores_dir = os.path.join(CUR_RES_ROOT_PATH, 'scores')\n",
    "    if not os.path.exists(scores_dir):\n",
    "        os.mkdir(scores_dir)\n",
    "    cfg_str = json.dumps(cur_cfg)\n",
    "    cfg_md5 = hashlib.md5(cfg_str).hexdigest()\n",
    "    cfg_fname = os.path.join(scores_dir, cfg_md5)\n",
    "    return cfg_fname\n",
    "\n",
    "def read_test_data_ids(cur_cfg, wnd_id, candidate_ids):\n",
    "    video = cur_cfg['video']\n",
    "    obj = cur_cfg['OBJECT']\n",
    "    testids_dir = os.path.join(CUR_RES_ROOT_PATH, 'testids')\n",
    "    if not os.path.exists(testids_dir):\n",
    "        os.mkdir(testids_dir)\n",
    "    testid_fname = os.path.join(testids_dir, video + '-' + obj + '-' + str(wnd_id))\n",
    "    if not os.path.exists(testid_fname):\n",
    "        print 'Create test id file...'\n",
    "        with open(testid_fname, 'wb') as f:\n",
    "            pickle.dump(candidate_ids, f)\n",
    "    with open(testid_fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def read_input(obj_ids, input_cfg, wnd_size_lst, img_sub_dirs,\n",
    "               img_sub_nums, cur_cfg, max_resol=(100, 100)):\n",
    "    print 'reading input for config:', input_cfg\n",
    "    train_num = input_cfg[0]\n",
    "    test_num = input_cfg[1]\n",
    "    wnd_num = input_cfg[2]\n",
    "    train_pos_ratio = input_cfg[3]\n",
    "    crop = str2ilst(input_cfg[4])\n",
    "    train_num_wnd = train_num / wnd_num\n",
    "    test_num_wnd = test_num / wnd_num\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    for i in range(wnd_num):\n",
    "        ids_wnd = range(sum(wnd_size_lst[:i]), sum(wnd_size_lst[:i+1]), 1)\n",
    "        test_ids_candidate = random.sample(ids_wnd, test_num_wnd)\n",
    "        test_ids_wnd = read_test_data_ids(cur_cfg, i, test_ids_candidate)\n",
    "        if len(test_ids_wnd) != test_num_wnd:\n",
    "            print 'test id number not matched!!!!!'\n",
    "            sys.exit()\n",
    "        \n",
    "        temp_ids_wnd = set(ids_wnd) - set(test_ids_wnd)\n",
    "        train_ids_pos_wnd_total = set(temp_ids_wnd) & set(obj_ids)\n",
    "        real_pos_ratio = float(len(train_ids_pos_wnd_total)) / len(temp_ids_wnd)\n",
    "        if train_pos_ratio < real_pos_ratio:\n",
    "            train_ids_wnd = random.sample(temp_ids_wnd, train_num_wnd)\n",
    "        else:\n",
    "            pos_num_needed = int(train_num_wnd * train_pos_ratio)\n",
    "            pos_num_needed = min(\n",
    "                pos_num_needed,\n",
    "                int(real_pos_ratio * train_num_wnd * 30), # at least 30 frames\n",
    "                len(train_ids_pos_wnd_total) / 2)\n",
    "            train_ids_pos_wnd = random.sample(\n",
    "                train_ids_pos_wnd_total, pos_num_needed)\n",
    "            train_ids_neg_wnd = random.sample(\n",
    "                temp_ids_wnd - train_ids_pos_wnd_total,\n",
    "                train_num_wnd - pos_num_needed)\n",
    "            train_ids_wnd = train_ids_pos_wnd + train_ids_neg_wnd\n",
    "            random.shuffle(train_ids_wnd)\n",
    "        train_ids += train_ids_wnd\n",
    "        test_ids += test_ids_wnd\n",
    "    X_train = get_frames_from_images(\n",
    "        train_ids, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop)\n",
    "    Y_train = get_labels(obj_ids, train_ids)\n",
    "    X_test = get_frames_from_images(\n",
    "        test_ids, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop)\n",
    "    Y_test = get_labels(obj_ids, test_ids)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def gen_model(resol, model_param, pre_model=None, model_type='AlexNet'):\n",
    "    if model_type == 'AlexNet':\n",
    "        param = ((resol[0], resol[1], 3), 2, model_param[0], model_param[1], model_param[2])\n",
    "        model = generate_conv_net_base(*param, lr_mult=0.001)\n",
    "    elif model_type == 'MobileNet':\n",
    "        model = keras.applications.mobilenet.MobileNet(\n",
    "            input_shape=(resol[0], resol[1], 3),\n",
    "            alpha=0.25, depth_multiplier=1, dropout=1e-3,\n",
    "            include_top=True, weights=None, classes=2)\n",
    "        model.compile(loss=get_loss(),\n",
    "                  optimizer=get_optimizer(lr_mult=0.001),\n",
    "                  metrics=computed_metrics)\n",
    "    else:\n",
    "        print ('No such model supported: ' + model_type)\n",
    "    if pre_model != None:\n",
    "        model.set_weights(pre_model.get_weights())\n",
    "    return model\n",
    "\n",
    "def run_models(X_train, Y_train, X_test, Y_test, video_cfg, cur_cfg):\n",
    "    nb_epoch=10\n",
    "    wnd_num = cur_cfg['input_cfg'][2]\n",
    "    out_file = os.path.join(CUR_RES_ROOT_PATH, cur_cfg['video'] + '.json')\n",
    "    resol = cur_cfg['resol']\n",
    "#     X_train_total = np.concatenate(X_train_wnds, axis=0)\n",
    "#     Y_train_total = np.concatenate(Y_train_wnds, axis=0)\n",
    "#     X_test_total = np.concatenate(X_test_wnds, axis=0)\n",
    "#     Y_test_total = np.concatenate(Y_test_wnds, axis=0)\n",
    "    \n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    save_mean(cur_cfg, mean)\n",
    "    X_train = X_train - mean\n",
    "    X_test = X_test - mean\n",
    "    \n",
    "    max_conv_num = int(math.log(min(resol), 2))\n",
    "    cfgs = []\n",
    "    for conv_num in range(max_conv_num):\n",
    "        for cfg in video_cfg['model']:\n",
    "            cfgs.append(cfg + ',' + str(conv_num + 1))\n",
    "    for model_cfg in cfgs:\n",
    "        print 'running cfg: ' + model_cfg\n",
    "        cur_cfg['model'] = model_cfg\n",
    "        param = str2ilst(model_cfg)\n",
    "        K.clear_session()\n",
    "        \n",
    "        cur_cfg['generic'] = True\n",
    "        if already_saved(json.dumps(cur_cfg), out_file):\n",
    "            print 'skip...'\n",
    "            continue\n",
    "        generic_model = gen_model(resol, param)\n",
    "        train_model(generic_model, X_train, Y_train, batch_size=32,\n",
    "                    nb_epoch=20, save_path=get_model_fname(cur_cfg))\n",
    "        scores = test_model(generic_model, X_test, Y_test)\n",
    "        add_json_file(json.dumps(cur_cfg), str(datetime.datetime.now()), out_file)\n",
    "        with open(get_score_fname(cur_cfg), 'w+') as f:\n",
    "            np.save(f, scores)\n",
    "        \n",
    "        cur_cfg['generic'] = False\n",
    "        total_scores = []\n",
    "        wnd_size_train = X_train.shape[0] / wnd_num\n",
    "        wnd_size_test = X_test.shape[0] / wnd_num\n",
    "        for i in range(wnd_num):\n",
    "            start_train = i * wnd_size_train\n",
    "            end_train = (i + 1) * wnd_size_train\n",
    "            start_test = i * wnd_size_test\n",
    "            end_test = (i + 1) * wnd_size_test\n",
    "            model = gen_model(resol, param, pre_model=generic_model)\n",
    "            train_model(model, X_train[start_train:end_train], Y_train[start_train:end_train],\n",
    "                        batch_size=32, nb_epoch=10, save_path=get_model_fname(cur_cfg) + '_' + str(i))\n",
    "            res = test_model(model, X_test[start_test:end_test], Y_test[start_test:end_test])\n",
    "            total_scores.append(res)\n",
    "        add_json_file(json.dumps(cur_cfg), str(datetime.datetime.now()), out_file)\n",
    "        total_scores = np.concatenate(total_scores, axis=0)\n",
    "        with open(get_score_fname(cur_cfg), 'w+') as f:\n",
    "            np.save(f, total_scores)\n",
    "        \n",
    "        \n",
    "def run_once(video_name, video_cfg):\n",
    "    # iterate input formats\n",
    "    video_clip_num = video_cfg['VIDEO_CLIP_NUM']\n",
    "    SMOOTH_WINDOW = FRAMES_PER_SEC * video_cfg['SMOOTH_SEC'] # for smooth the yolo output\n",
    "    input_cfgs = list(itertools.product(\n",
    "        video_cfg['train_num'],\n",
    "        video_cfg['test_num'],\n",
    "        video_cfg['wnd_num'],\n",
    "        video_cfg['train_pos_ratio'],\n",
    "        video_cfg['crop']\n",
    "    ))\n",
    "    sub_videos = [video_name + '-' + str(p + 1) + '_10FPS' for p in range(video_clip_num)]\n",
    "    img_sub_dirs = [os.path.join(JPG_ROOT_PATH, v) for v in sub_videos]\n",
    "    img_sub_nums = [len(os.listdir(d)) for d in img_sub_dirs]\n",
    "    total_frame_num = sum(img_sub_nums)\n",
    "    csv_sub_files = [os.path.join(CSV_ROOT_PATH, d + '.csv') for d in sub_videos]\n",
    "    cur_cfg = {'video': video_name, 'smooth_window': SMOOTH_WINDOW}\n",
    "    for OBJECT in video_cfg['OBJECT']:\n",
    "        cur_cfg['OBJECT'] = OBJECT\n",
    "        for input_cfg in input_cfgs:\n",
    "            cur_cfg['input_cfg'] = input_cfg\n",
    "            obj_ids, _ = get_csv_samples_many(\n",
    "                csv_sub_files, img_sub_nums, OBJECT, total_frame_num,\n",
    "                WINDOW=SMOOTH_WINDOW, crop=str2ilst(input_cfg[4]))\n",
    "#             obj_ids_test, _ = get_csv_samples_many(\n",
    "#                 csv_sub_files, img_sub_nums, OBJECT, total_frame_num,\n",
    "#                 WINDOW=SMOOTH_WINDOW, crop=None)\n",
    "            resol_lst = [str2ilst(r) for r in video_cfg['resol']]\n",
    "            max_resol = (max([r[0] for r in resol_lst]), max([r[1] for r in resol_lst]))\n",
    "            X_train, Y_train, X_test, Y_test = read_input(\n",
    "                obj_ids, input_cfg, img_sub_nums, img_sub_dirs,\n",
    "                img_sub_nums, cur_cfg, max_resol=max_resol)\n",
    "            for resol in resol_lst:\n",
    "                cur_cfg['resol'] = resol\n",
    "                if resol[0] != max_resol[0] or resol[1] != max_resol[1]:\n",
    "                    resized_X_train = resize_images(X_train, resol, dtype='float32')\n",
    "                    resized_X_test = resize_images(X_test, resol, dtype='float32')\n",
    "                else:\n",
    "                    resized_X_train = X_train\n",
    "                    resized_X_test = X_test\n",
    "                run_models(resized_X_train, Y_train, resized_X_test, Y_test, video_cfg, cur_cfg)\n",
    "                resized_X_train = None\n",
    "                resized_X_test = None\n",
    "                gc.collect()\n",
    "            X_train = None\n",
    "            X_test = None\n",
    "            Y_train = None\n",
    "            Y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# automate experiments\n",
    "with open('exp_params.cfg') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "run_video = 'venice-canal'\n",
    "CUR_RES_ROOT_PATH = os.path.join(RES_ROOT_PATH, run_video)\n",
    "if not os.path.exists(CUR_RES_ROOT_PATH):\n",
    "    os.mkdir(CUR_RES_ROOT_PATH)\n",
    "for video in cfg.keys():\n",
    "    if video != run_video: continue\n",
    "    run_once(video, cfg[video])\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## test background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the background subtraction\n",
    "video_name = 'zoo'\n",
    "obj = 'person'\n",
    "video_clip_num = 8\n",
    "\n",
    "%run util.py\n",
    "\n",
    "sub_videos = [video_name + '-' + str(p + 1) + '_10FPS' for p in range(video_clip_num)]\n",
    "img_sub_dirs = [os.path.join(JPG_ROOT_PATH, v) for v in sub_videos]\n",
    "img_sub_nums = [len(os.listdir(d)) for d in img_sub_dirs]\n",
    "total_frame_num = sum(img_sub_nums)\n",
    "\n",
    "csv_sub_files = [os.path.join(CSV_ROOT_PATH, d + '.csv') for d in sub_videos]\n",
    "obj_ids, _ = get_csv_samples_many(\n",
    "    csv_sub_files, img_sub_nums, obj, total_frame_num,\n",
    "    WINDOW=50, crop=None)\n",
    "\n",
    "\n",
    "fgbg_dict = {}\n",
    "out_dir = '/host/4TB_hybridvs_data/YOLO-RES-720P/fgbg/'\n",
    "for i in range(video_clip_num):\n",
    "    out_fname = os.path.join(out_dir, video_name + '-' + str(i + 1))\n",
    "    with open(out_fname, 'rb') as f:\n",
    "        base = sum(img_sub_nums[:i])\n",
    "        res = (pickle.load(f))\n",
    "        for jpg in res:\n",
    "            idx = int(jpg[:-4]) + base\n",
    "            fgbg_dict[idx] = res[jpg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_box(matches):\n",
    "    min_x = min(m[0] for m in matches)\n",
    "    min_y = min(m[1] for m in matches)\n",
    "    max_x = max(m[2] for m in matches)\n",
    "    max_y = max(m[3] for m in matches)\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "def contain_rect(br, sr):\n",
    "    return br[0] <= sr[0] and br[1] <= sr[1] and br[2] >= sr[2] and br[3] >= sr[3]\n",
    "\n",
    "def convert(crop):\n",
    "    return (crop[1], crop[0], crop[1] + crop[3], crop[0] + crop[2])\n",
    "\n",
    "def get_frames_from_images(frameset, img_dirs, img_nums, fgmask_dict=None,\n",
    "                           resol=(-1, -1), crop=(-1, -1, -1, -1), dtype='float32'):\n",
    "    def get_image_path(idx):\n",
    "        for i in range(len(img_dirs)):\n",
    "            if sum(img_nums[:i + 1]) > idx:\n",
    "                return os.path.join(img_dirs[i], str(idx - sum(img_nums[:i]) + 1).zfill(7) + '.jpg')\n",
    "    assert len(img_dirs) == len(img_nums), 'image subdir numbers not consistent!'\n",
    "#     print ('reading images... %d from %s...') % (len(frameset), img_dirs[0])\n",
    "    if resol[0] > 0:\n",
    "        frames = np.zeros(tuple([len(frameset)] + list(resol) + [3]), dtype=dtype )\n",
    "    else:\n",
    "        test_frame = cv2.imread(os.path.join(img_dirs[0], '0000001.jpg'))\n",
    "        frames = np.zeros(tuple([len(frameset)] + list(test_frame.shape)), dtype=dtype )\n",
    "    for i in range(len(frameset)):\n",
    "        img_path = get_image_path(frameset[i])\n",
    "        frame = cv2.imread(img_path)\n",
    "        tmp_crop = deepcopy(crop)\n",
    "        if fgmask_dict is not None:\n",
    "            tmp_idx = frameset[i]\n",
    "            while tmp_idx not in fgmask_dict:\n",
    "                tmp_idx -= 1\n",
    "            boxes = fgmask_dict[tmp_idx]\n",
    "            boxes = [b for b in boxes if b[2] > 40 and b[3] > 40]\n",
    "            boxes = [convert(b) for b in boxes]\n",
    "            if tmp_crop[0] > 0:\n",
    "                boxes = [b for b in boxes if contain_rect(tmp_crop, b)]\n",
    "            if len(boxes) > 0:\n",
    "                tmp_crop = get_big_box(boxes)\n",
    "        if tmp_crop[0] > 0:\n",
    "            frame = frame[tmp_crop[0]:tmp_crop[2],tmp_crop[1]:tmp_crop[3],:]\n",
    "        if resol[0] > 0:\n",
    "            frame = cv2.resize(frame, (resol[1], resol[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        frames[i, :] = frame\n",
    "\n",
    "    if dtype == 'float32':\n",
    "        frames /= 255.0\n",
    "\n",
    "    return frames\n",
    "\n",
    "max_num = max(fgbg_dict.keys())\n",
    "train_ids = random.sample(range(max_num), 24000)\n",
    "test_ids = random.sample(range(max_num), 20000)\n",
    "\n",
    "X_train = get_frames_from_images(\n",
    "    train_ids, img_sub_dirs, img_sub_nums, fgmask_dict=fgbg_dict,\n",
    "    resol=(50,50), crop=(-1,-1,-1,-1), dtype='float32')\n",
    "Y_train = get_labels(obj_ids, train_ids)\n",
    "X_test = get_frames_from_images(\n",
    "    test_ids, img_sub_dirs, img_sub_nums, fgmask_dict=fgbg_dict,\n",
    "    resol=(50,50), crop=(-1,-1,-1,-1), dtype='float32')\n",
    "Y_test = get_labels(obj_ids, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "    \n",
    "showarray(X_train[8000,:] * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_model((r1, r2), nb_dense, nb_filters, nb_layers, pre_model=None):\n",
    "    param = ((r1, r2, 3), 2, nb_dense, nb_filters, nb_layers)\n",
    "    model = generate_conv_net_base(*param, lr_mult=0.001)\n",
    "    return model\n",
    "\n",
    "def train_test(param, cur_X_train, cur_Y_train, cur_X_test, cur_Y_test):\n",
    "    K.clear_session()\n",
    "    model = gen_model(*param)\n",
    "    train_model(model, cur_X_train, cur_Y_train, batch_size=32, nb_epoch=20)\n",
    "    scores = test_model(model, cur_X_test, cur_Y_test, batch_size=128)\n",
    "    return cal_scores(scores), cal_score_filter(scores)\n",
    "\n",
    "\n",
    "acc1 = train_test(((50,50),32,16,5), X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print acc1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = get_frames_from_images(\n",
    "    train_ids, img_sub_dirs, img_sub_nums, fgmask_dict=None,\n",
    "    resol=(50,50), crop=(-1,-1,-1,-1), dtype='float32')\n",
    "X_test_2 = get_frames_from_images(\n",
    "    test_ids, img_sub_dirs, img_sub_nums, fgmask_dict=None,\n",
    "    resol=(50,50), crop=(-1,-1,-1,-1), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc2 = train_test(((50,50),32,16,5), X_train_2, Y_train, X_test_2, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print acc2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def read_input(obj_ids, obj_ids_test, input_cfg, wnd_size_lst, img_sub_dirs,\n",
    "#                img_sub_nums, cur_cfg, max_resol=(100, 100)):\n",
    "#     print 'reading input for config:', input_cfg\n",
    "#     train_num = input_cfg[0]\n",
    "#     test_num = input_cfg[1]\n",
    "#     wnd_num = input_cfg[2]\n",
    "#     train_pos_ratio = input_cfg[3]\n",
    "#     crop = str2ilst(input_cfg[4])\n",
    "#     train_num_wnd = train_num / wnd_num\n",
    "#     test_num_wnd = test_num / wnd_num\n",
    "#     frame_ids_wnd = []\n",
    "#     train_ids = []\n",
    "#     X_train_wnds = []\n",
    "#     Y_train_wnds = []\n",
    "#     test_ids = []\n",
    "#     X_test_wnds = []\n",
    "#     Y_test_wnds = []\n",
    "#     for i in range(wnd_num):\n",
    "#         print 'processing time window: ', i\n",
    "#         ids_wnd = range(sum(wnd_size_lst[:i]), sum(wnd_size_lst[:i+1]), 1)\n",
    "#         least_pos_test_ids = random.sample(obj_ids, 5)\n",
    "#         test_ids_candidate = least_pos_test_ids + random.sample(\n",
    "#             set(ids_wnd) - set(least_pos_test_ids), test_num_wnd - 5)\n",
    "#         test_ids_wnd = read_test_data_ids(cur_cfg, i, test_ids_candidate)\n",
    "#         if len(test_ids_wnd) != test_num_wnd:\n",
    "#             print 'test id number not matched!!!!!'\n",
    "#             sys.exit()\n",
    "#         temp_ids_wnd = [x for x in ids_wnd if x not in test_ids_wnd]\n",
    "#         if train_pos_ratio < 0:\n",
    "#             train_ids_wnd = random.sample(temp_ids_wnd, train_num_wnd)\n",
    "#         else:\n",
    "#             train_ids_pos_wnd_total = [x for x in temp_ids_wnd if x in obj_ids]\n",
    "#             pos_num_needed = int(train_num_wnd * train_pos_ratio)\n",
    "#             if len(train_ids_pos_wnd_total) < pos_num_needed:\n",
    "#                 pos_num_needed = len(train_ids_pos_wnd_total) / 2\n",
    "#             train_ids_pos_wnd = random.sample(\n",
    "#                 train_ids_pos_wnd_total, pos_num_needed)\n",
    "#             train_ids_neg_wnd = random.sample(\n",
    "#                 [x for x in temp_ids_wnd if x not in obj_ids],\n",
    "#                 int(train_num_wnd * (1 - train_pos_ratio)))\n",
    "#             train_ids_wnd = train_ids_pos_wnd + train_ids_neg_wnd\n",
    "#             random.shuffle(train_ids_wnd)\n",
    "#         train_ids.append(train_ids_wnd)\n",
    "#         test_ids.append(test_ids_wnd)\n",
    "#         X_train_wnds.append(get_frames_from_images(\n",
    "#             train_ids_wnd, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop))\n",
    "#         Y_train_wnds.append(get_labels(obj_ids, train_ids_wnd))\n",
    "#         X_test_wnds.append(get_frames_from_images(\n",
    "#             test_ids_wnd, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop))\n",
    "#         Y_test_wnds.append(get_labels(obj_ids_test, test_ids_wnd))\n",
    "#     return X_train_wnds, Y_train_wnds, X_test_wnds, Y_test_wnds\n",
    "\n",
    "\n",
    "# with open('exp_params.cfg') as f:\n",
    "#     cfg = json.load(f)\n",
    "\n",
    "# video_name = 'banff'\n",
    "# video_cfg = cfg[video_name]\n",
    "\n",
    "# video_clip_num = video_cfg['VIDEO_CLIP_NUM']\n",
    "# input_cfgs = list(itertools.product(\n",
    "#     video_cfg['train_num'],\n",
    "#     video_cfg['test_num'],\n",
    "#     video_cfg['wnd_num'],\n",
    "#     video_cfg['train_pos_ratio'],\n",
    "#     video_cfg['crop']\n",
    "# ))\n",
    "# sub_videos = [video_name + '-' + str(p + 1) for p in range(video_clip_num)]\n",
    "# img_sub_dirs = [os.path.join(JPG_ROOT_PATH, v) for v in sub_videos]\n",
    "# img_sub_dirs = [x + '_10FPS' for x in img_sub_dirs]\n",
    "# img_sub_nums = [len(os.listdir(d)) for d in img_sub_dirs]\n",
    "# total_frame_num = sum(img_sub_nums)\n",
    "# csv_sub_files = [os.path.join(CSV_ROOT_PATH, d + '_10FPS.csv') for d in sub_videos]\n",
    "# cur_cfg = {'video': video_name}\n",
    "# OBJECT = video_cfg['OBJECT'][0]\n",
    "# cur_cfg['OBJECT'] = OBJECT\n",
    "# input_cfg = input_cfgs[0]\n",
    "# print input_cfg\n",
    "# cur_cfg['input_cfg'] = input_cfg\n",
    "# obj_ids, _ = get_csv_samples_many(\n",
    "#     csv_sub_files, img_sub_nums, OBJECT, total_frame_num,\n",
    "#     WINDOW=60, crop=str2ilst(input_cfg[4]))\n",
    "# obj_ids_test, _ = get_csv_samples_many(\n",
    "#     csv_sub_files, img_sub_nums, OBJECT, total_frame_num,\n",
    "#     WINDOW=60, crop=None)\n",
    "# _resol = video_cfg['resol'][0]\n",
    "# resol = str2ilst(_resol)\n",
    "# cur_cfg['resol'] = resol\n",
    "# X_train_wnds, Y_train_wnds, X_test_wnds, Y_test_wnds = read_input(\n",
    "#     obj_ids, obj_ids_test, input_cfg, img_sub_nums, img_sub_dirs, img_sub_nums, cur_cfg, max_resol=resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_cfg2 = (input_cfg[0], input_cfg[1], input_cfg[2], input_cfg[3], \"550,300,720,550\")\n",
    "# X_train_wnds2, Y_train_wnds2, X_test_wnds2, Y_test_wnds2 = read_input(\n",
    "#     obj_ids, obj_ids_test, input_cfg2, img_sub_nums, img_sub_dirs, img_sub_nums, cur_cfg, max_resol=resol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def showarray(a, fmt='png'):\n",
    "#     a = np.uint8(a)\n",
    "#     f = StringIO()\n",
    "#     PIL.Image.fromarray(a).save(f, fmt)\n",
    "#     IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "# showarray(X_train_wnds[0][0] * 255)\n",
    "# showarray(X_train_wnds2[0][0] * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nb_epoch=10\n",
    "# conv_num = 4\n",
    "# resol = cur_cfg['resol']\n",
    "# X_train_total = np.concatenate(X_train_wnds, axis=0)\n",
    "# Y_train_total = np.concatenate(Y_train_wnds, axis=0)\n",
    "# X_test_total = np.concatenate(X_test_wnds, axis=0)\n",
    "# Y_test_total = np.concatenate(Y_test_wnds, axis=0)\n",
    "# mean = np.mean(X_train_total, axis=0)\n",
    "# X_train_total = X_train_total - mean\n",
    "# X_test_total = X_test_total - mean\n",
    "# max_conv_num = int(math.log(min(resol), 2))\n",
    "# print video_cfg\n",
    "# model_cfg = video_cfg['model'][0]\n",
    "# model_cfg = model_cfg + ',' + str(conv_num)\n",
    "# print 'running cfg: ' + model_cfg\n",
    "# cur_cfg['model'] = model_cfg\n",
    "# param = str2ilst(model_cfg)\n",
    "# K.clear_session()\n",
    "# generic_model = gen_model(resol, param)\n",
    "# # generic_model = generate_conv_net_base2()\n",
    "# train_model(generic_model, X_train_total, Y_train_total, batch_size=64,\n",
    "#             nb_epoch=nb_epoch)\n",
    "# scores = test_model(generic_model, X_test_total, Y_test_total)\n",
    "# print cal_score_filter(scores)\n",
    "        \n",
    "# cur_cfg['generic'] = False\n",
    "# pos_idxs_lst = []\n",
    "# for i in range(len(X_train_wnds)):\n",
    "#     model = gen_model(resol, param, pre_model=generic_model)\n",
    "#     train_model(model, X_train_wnds[i], Y_train_wnds[i], batch_size=32,\n",
    "#                 nb_epoch=10, save_path=get_model_fname(cur_cfg) + '_' + str(i))\n",
    "#     accuracy, pos_idxs = test_model(model, X_test_wnds[i], Y_test_wnds[i],\n",
    "#                                     save_fname=get_score_fname(cur_cfg) + '_' + str(i))\n",
    "#     pos_idxs_lst.append(pos_idxs)\n",
    "# formated_acc = cal_accuracy_many(pos_idxs_lst, error_list=[0.5, 0.1, 0.01])\n",
    "# print formated_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formated_acc = cal_accuracy(pos_idxs[0], pos_idxs[1], error_list=[0.5, 0.1, 0.01])\n",
    "# print formated_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:102: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(1, 1), input_shape=(100, 100,...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "<string>:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\")`\n",
      "<string>:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "<string>:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(160, (3, 3), padding=\"same\")`\n",
      "<string>:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50, 50, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25, 25, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       110720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 160)         184480    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 160)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 160)         640       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 3, 160)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 160)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 192)         276672    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 192)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1, 1, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 192)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                12352     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 661,826\n",
      "Trainable params: 660,482\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "param = ((100, 100, 3), 2, 64, 32, 6)\n",
    "model = generate_conv_net_base(*param, lr_mult=0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n",
      "1325620\n"
     ]
    }
   ],
   "source": [
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=K.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops  # Prints the \"flops\" of the model.\n",
    "\n",
    "\n",
    "# .... Define your model here ....\n",
    "print(get_flops(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 7487/15000\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 6s 418us/step - loss: 0.7195 - acc: 0.5009 - mean_squared_error: 0.0924\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 5s 344us/step - loss: 0.6977 - acc: 0.5022 - mean_squared_error: 0.0840\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.6971 - acc: 0.4978 - mean_squared_error: 0.0837\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 5s 341us/step - loss: 0.6970 - acc: 0.5009 - mean_squared_error: 0.0836\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 5s 344us/step - loss: 0.6968 - acc: 0.5015 - mean_squared_error: 0.0836\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 5s 341us/step - loss: 0.6968 - acc: 0.4974 - mean_squared_error: 0.0835\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 5s 344us/step - loss: 0.6968 - acc: 0.4949 - mean_squared_error: 0.0835\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 5s 342us/step - loss: 0.6968 - acc: 0.4998 - mean_squared_error: 0.0835\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.6967 - acc: 0.4979 - mean_squared_error: 0.0835\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 5s 346us/step - loss: 0.6967 - acc: 0.4986 - mean_squared_error: 0.0835\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.6967 - acc: 0.5002 - mean_squared_error: 0.0835\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 5s 340us/step - loss: 0.6967 - acc: 0.5031 - mean_squared_error: 0.0835\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 5s 339us/step - loss: 0.6967 - acc: 0.5056 - mean_squared_error: 0.0835\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 5s 342us/step - loss: 0.6967 - acc: 0.5051 - mean_squared_error: 0.0835\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 5s 340us/step - loss: 0.6967 - acc: 0.5023 - mean_squared_error: 0.0835\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 5s 344us/step - loss: 0.6967 - acc: 0.4910 - mean_squared_error: 0.0835\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.6967 - acc: 0.5016 - mean_squared_error: 0.0835\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 5s 341us/step - loss: 0.6967 - acc: 0.4994 - mean_squared_error: 0.0835\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.6967 - acc: 0.5029 - mean_squared_error: 0.0835\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 5s 341us/step - loss: 0.6967 - acc: 0.5006 - mean_squared_error: 0.0835\n"
     ]
    }
   ],
   "source": [
    "def train_test(param, cur_X_train, cur_Y_train):\n",
    "    K.clear_session()\n",
    "    model = gen_model(*param)\n",
    "    train_model(model, cur_X_train, cur_Y_train, batch_size=32, nb_epoch=20)\n",
    "\n",
    "def gen_model((r1, r2), nb_dense, nb_filters, nb_layers, pre_model=None):\n",
    "    param = ((r1, r2, 3), 2, nb_dense, nb_filters, nb_layers)\n",
    "    model = generate_conv_net_base(*param, lr_mult=0.001)\n",
    "    return model\n",
    "\n",
    "X_train = np.random.random((15000,50,50,3))\n",
    "Y_train = np.random.random((15000,2))\n",
    "acc1 = train_test(((50,50),64,32,5), X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
