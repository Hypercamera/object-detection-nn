{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# FIXME refactor the rest of code and remove this line in the future\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import itertools\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import json\n",
    "import hashlib\n",
    "import tempfile\n",
    "import keras.optimizers\n",
    "import pickle\n",
    "import datetime\n",
    "import cv2\n",
    "import math\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape\n",
    "import ast\n",
    "import h5py\n",
    "from keras.utils import np_utils\n",
    "from itertools import tee\n",
    "# import keras.backend as K\n",
    "import tensorflow as tf\n",
    "# from tensorflow import Keras as K\n",
    "\n",
    "from copy import deepcopy\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "#from cStringIO import StringIO\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from util import get_csv_samples_many\n",
    "\n",
    "%run exp_util.py\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "# keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import pickle\n",
    "# import cv2\n",
    "# from copy import deepcopy\n",
    "# import time\n",
    "# import keras.optimizers\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.models import Sequential, load_model\n",
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Convolution2D, MaxPooling2D, Reshape\n",
    "# from keras.utils import np_utils\n",
    "# import keras.backend as K\n",
    "# import gc, os, itertools\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "# from util import get_csv_samples_many\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# %run util.py\n",
    "\n",
    "\n",
    "\n",
    "# FIXME for debuging\n",
    "INIT_FLAG = False\n",
    "VARIABLE_STORAGE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg_dict = {}\n",
    "\n",
    "def gen_model(resol, model_param, pre_model=None, model_type='AlexNet'):\n",
    "    if model_type == 'AlexNet':\n",
    "        param = ((resol[0], resol[1], 3), 2, model_param[0], model_param[1], model_param[2])\n",
    "        model = generate_conv_net_base(*param, lr_mult=0.001)\n",
    "    elif model_type == 'MobileNet':\n",
    "        model = tf.keras.applications.mobilenet.MobileNet(\n",
    "            input_shape=(resol[0], resol[1], 3),\n",
    "            alpha=0.25, depth_multiplier=1, dropout=1e-3,\n",
    "            include_top=True, weights=None, classes=2)\n",
    "        model.compile(loss=get_loss(),\n",
    "                  optimizer=get_optimizer(lr_mult=0.001),\n",
    "                  metrics=computed_metrics)\n",
    "    else:\n",
    "        print ('No such model supported: ' + model_type)\n",
    "    if pre_model != None:\n",
    "        model.set_weights(pre_model.get_weights())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2ilst(s):\n",
    "    return [int(x) for x in s.split(',')]\n",
    "\n",
    "def add_json_file(key, val, fname):\n",
    "    \"\"\"\n",
    "    Retrive data from given JSON file and update / insert an entry based on the given key\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname) as f:\n",
    "            res = json.load(f)\n",
    "    res[key] = val\n",
    "    with open(fname, 'w+') as out_f:\n",
    "        json.dump(res, out_f)\n",
    "        \n",
    "def get_score_fname(cur_cfg):\n",
    "    \"\"\"\n",
    "    Take the value of cur_cfg and encode it by utf-8 and hash it.\n",
    "    \"\"\"\n",
    "    scores_dir = os.path.join(CUR_RES_ROOT_PATH, 'scores')\n",
    "    if not os.path.exists(scores_dir):\n",
    "        os.mkdir(scores_dir)\n",
    "    cfg_str = json.dumps(cur_cfg)\n",
    "    cfg_md5 = hashlib.md5(cfg_str.encode(\"utf-8\")).hexdigest()\n",
    "    cfg_fname = os.path.join(scores_dir, cfg_md5)\n",
    "    return cfg_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place for constants\n",
    "\n",
    "FRAMES_PER_SEC = 10 # frame rate we decode the video\n",
    "FULL_RESOL = (720, 1280) # default 720p\n",
    "\n",
    "RES_ROOT_PATH=\"/media/YOLO-RES-720P/exp\"\n",
    "JPG_ROOT_PATH=\"/media/YOLO-RES-720P/jpg\"\n",
    "CSV_ROOT_PATH=\"/media/YOLO-RES-720P/out\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor\n",
    "# * epoch should be passed in from outter function\n",
    "# * wnd_num? what is that?\n",
    "# * remove K (kears), use TF.kears to replace it\n",
    "def add_json_file(key, val, fname):\n",
    "    res = {}\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname) as f:\n",
    "            res = json.load(f)\n",
    "    res[key] = val\n",
    "    with open(fname, 'w+') as out_f:\n",
    "        json.dump(res, out_f)\n",
    "\n",
    "def run_models(X_train, Y_train, X_test, Y_test, video_cfg, cur_cfg):\n",
    "    nb_epoch=10\n",
    "    wnd_num = cur_cfg['input_cfg'][2]\n",
    "    out_file = os.path.join(CUR_RES_ROOT_PATH, cur_cfg['video'] + '.json')\n",
    "    resol = cur_cfg['resol']\n",
    "#     X_train_total = np.concatenate(X_train_wnds, axis=0)\n",
    "#     Y_train_total = np.concatenate(Y_train_wnds, axis=0)\n",
    "#     X_test_total = np.concatenate(X_test_wnds, axis=0)\n",
    "#     Y_test_total = np.concatenate(Y_test_wnds, axis=0)\n",
    "    \n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    save_mean(cur_cfg, mean)\n",
    "    X_train = X_train - mean\n",
    "    X_test = X_test - mean\n",
    "    \n",
    "    max_conv_num = int(math.log(min(resol), 2))\n",
    "    cfgs = []\n",
    "    for conv_num in range(max_conv_num):\n",
    "        for cfg in video_cfg['model']:\n",
    "            cfgs.append(cfg + ',' + str(conv_num + 1))\n",
    "    \n",
    "    # FIXME stop here, check parameters\n",
    "    #print(f'cfgs: {cfgs}')\n",
    "    #return\n",
    "    # FIXME remember to remove the above\n",
    "    \n",
    "    for model_cfg in cfgs:\n",
    "        print ('running cfg: ' + model_cfg)\n",
    "        cur_cfg['model'] = model_cfg\n",
    "        param = str2ilst(model_cfg)\n",
    "        #K.clear_session()\n",
    "        # FIXME compatible\n",
    "        tf.compat.v2.keras.backend.clear_session()\n",
    "        \n",
    "        cur_cfg['generic'] = True\n",
    "        if already_saved(json.dumps(cur_cfg), out_file):\n",
    "            print ('skip...')\n",
    "            continue\n",
    "        generic_model = gen_model(resol, param)\n",
    "        \n",
    "        # FIXME train model indicator\n",
    "        train_start = time.time()\n",
    "        \n",
    "        print(\"----------------------Training---------------------------------\")\n",
    "        \n",
    "        train_model(generic_model, X_train, Y_train, batch_size=32,\n",
    "                    nb_epoch=20, save_path=get_model_fname(cur_cfg))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # FIXME train model indicator\n",
    "        train_done = time.time()\n",
    "        print(f'time diff {train_done - train_start}')\n",
    "        print(\"----------------------Training done---------------------------------\")\n",
    "        \n",
    "        \n",
    "        scores = test_model(generic_model, X_test, Y_test)\n",
    "        \n",
    "        # FIXME debuging\n",
    "        global INIT_FLAG\n",
    "        global VARIABLE_STORAGE\n",
    "        if (not INIT_FLAG):\n",
    "            VARIABLE_STORAGE = scores\n",
    "            INIT_FLAG = True\n",
    "            print('VARIABLE_STORAGE')\n",
    "            print(VARIABLE_STORAGE)\n",
    "            print(f'out_file: {out_file}')\n",
    "            print(f'get_score_fname(cur_cfg): {get_score_fname(cur_cfg)}')\n",
    "            raise MemoryError(\"STOP HERE, debug\")\n",
    "\n",
    "        add_json_file(json.dumps(cur_cfg), str(datetime.datetime.now()), out_file)\n",
    "\n",
    "        with open(get_score_fname(cur_cfg), 'wb+') as f:\n",
    "            np.save(f, scores)\n",
    "        \n",
    "        cur_cfg['generic'] = False\n",
    "        total_scores = []\n",
    "        wnd_size_train = X_train.shape[0] // wnd_num\n",
    "        wnd_size_test = X_test.shape[0] // wnd_num\n",
    "        for i in range(wnd_num):\n",
    "            start_train = i * wnd_size_train\n",
    "            end_train = (i + 1) * wnd_size_train\n",
    "            start_test = i * wnd_size_test\n",
    "            end_test = (i + 1) * wnd_size_test\n",
    "            model = gen_model(resol, param, pre_model=generic_model)\n",
    "            train_model(model, X_train[start_train:end_train], Y_train[start_train:end_train],\n",
    "                        batch_size=32, nb_epoch=10, save_path=get_model_fname(cur_cfg) + '_' + str(i))\n",
    "            res = test_model(model, X_test[start_test:end_test], Y_test[start_test:end_test])\n",
    "            total_scores.append(res)\n",
    "        add_json_file(json.dumps(cur_cfg), str(datetime.datetime.now()), out_file)\n",
    "        total_scores = np.concatenate(total_scores, axis=0)\n",
    "        with open(get_score_fname(cur_cfg), 'wb+') as f:\n",
    "            np.save(f, total_scores)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(frames, resol, dtype='float32'):\n",
    "    new_frames = np.zeros(tuple([frames.shape[0]] + list(resol) + [3]), dtype=dtype)\n",
    "    for i in range(frames.shape[0]):\n",
    "        one_frame = cv2.resize(frames[i,:,:,:], (resol[1], resol[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        new_frames[i, :] = one_frame\n",
    "    return new_frames\n",
    "\n",
    "def cfg2mean(cfg):\n",
    "    tag = ','.join([str(cfg['resol'][0]), str(cfg['resol'][1]), cfg['input_cfg'][-1]])\n",
    "    return tag\n",
    "\n",
    "def save_mean(cfg, mean):\n",
    "    cfg_tag = cfg2mean(cfg)\n",
    "    mean_dir = os.path.join(RES_ROOT_PATH, cfg['video'], 'mean')\n",
    "    if not os.path.exists(mean_dir):\n",
    "        os.mkdir(mean_dir)\n",
    "    mean_fname = os.path.join(mean_dir, cfg_tag)\n",
    "    np.save(mean_fname, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data_ids(cur_cfg, wnd_id, candidate_ids):\n",
    "    video = cur_cfg['video']\n",
    "    obj = cur_cfg['OBJECT']\n",
    "    testids_dir = os.path.join(CUR_RES_ROOT_PATH, 'testids')\n",
    "    if not os.path.exists(testids_dir):\n",
    "        os.mkdir(testids_dir)\n",
    "    testid_fname = os.path.join(testids_dir, video + '-' + obj + '-' + str(wnd_id))\n",
    "    if not os.path.exists(testid_fname):\n",
    "        print('Create test id file...')\n",
    "        with open(testid_fname, 'wb') as f:\n",
    "            pickle.dump(candidate_ids, f)\n",
    "    with open(testid_fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_box(matches):\n",
    "    min_x = min(m[0] for m in matches)\n",
    "    min_y = min(m[1] for m in matches)\n",
    "    max_x = max(m[2] for m in matches)\n",
    "    max_y = max(m[3] for m in matches)\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "def contain_rect(br, sr):\n",
    "    return br[0] <= sr[0] and br[1] <= sr[1] and br[2] >= sr[2] and br[3] >= sr[3]\n",
    "\n",
    "def convert(crop):\n",
    "    return (crop[1], crop[0], crop[1] + crop[3], crop[0] + crop[2])\n",
    "\n",
    "def get_frames_from_images(frameset, img_dirs, img_nums, fgmask_dict=None,\n",
    "                           resol=(-1, -1), crop=(-1, -1, -1, -1), dtype='float32'):\n",
    "    def get_image_path(idx):\n",
    "        for i in range(len(img_dirs)):\n",
    "            if sum(img_nums[:i + 1]) > idx:\n",
    "                return os.path.join(img_dirs[i], str(idx - sum(img_nums[:i]) + 1).zfill(7) + '.jpg')\n",
    "    assert len(img_dirs) == len(img_nums), 'image subdir numbers not consistent!'\n",
    "#     print ('reading images... %d from %s...') % (len(frameset), img_dirs[0])\n",
    "    if resol[0] > 0:\n",
    "        frames = np.zeros(tuple([len(frameset)] + list(resol) + [3]), dtype=dtype )\n",
    "    else:\n",
    "        test_frame = cv2.imread(os.path.join(img_dirs[0], '0000001.jpg'))\n",
    "        frames = np.zeros(tuple([len(frameset)] + list(test_frame.shape)), dtype=dtype )\n",
    "    for i in range(len(frameset)):\n",
    "        img_path = get_image_path(frameset[i])\n",
    "        frame = cv2.imread(img_path)\n",
    "        tmp_crop = deepcopy(crop)\n",
    "        if fgmask_dict is not None:\n",
    "            tmp_idx = frameset[i]\n",
    "            while tmp_idx not in fgmask_dict:\n",
    "                tmp_idx -= 1\n",
    "            boxes = fgmask_dict[tmp_idx]\n",
    "            boxes = [b for b in boxes if b[2] > 40 and b[3] > 40]\n",
    "            boxes = [convert(b) for b in boxes]\n",
    "            if tmp_crop[0] > 0:\n",
    "                boxes = [b for b in boxes if contain_rect(tmp_crop, b)]\n",
    "            if len(boxes) > 0:\n",
    "                tmp_crop = get_big_box(boxes)\n",
    "        if tmp_crop[0] > 0:\n",
    "            frame = frame[tmp_crop[0]:tmp_crop[2],tmp_crop[1]:tmp_crop[3],:]\n",
    "        if resol[0] > 0:\n",
    "            frame = cv2.resize(frame, (resol[1], resol[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        frames[i, :] = frame\n",
    "\n",
    "    if dtype == 'float32':\n",
    "        frames /= 255.0\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(obj_ids, frameset):\n",
    "    ret = [t in obj_ids for t in frameset]\n",
    "    print('reading label sum: %d, pos %d'%(len(ret), sum(ret)))\n",
    "    return np_utils.to_categorical(ret, 2)\n",
    "\n",
    "def already_saved(key, fname):\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname) as f:\n",
    "            res = json.load(f)\n",
    "            if key in res: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_input(obj_ids, input_cfg, wnd_size_lst, img_sub_dirs,\n",
    "               img_sub_nums, cur_cfg, max_resol=(100, 100)):\n",
    "    \n",
    "    # FIXME this function take long time to run... Need to optimize this function\n",
    "    print('reading input for config:', input_cfg)\n",
    "    train_num = input_cfg[0]\n",
    "    test_num = input_cfg[1]\n",
    "    wnd_num = input_cfg[2]\n",
    "    train_pos_ratio = input_cfg[3]\n",
    "    crop = str2ilst(input_cfg[4])\n",
    "    train_num_wnd = train_num // wnd_num\n",
    "    test_num_wnd = test_num // wnd_num\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    \n",
    "    for i in range(wnd_num):\n",
    "        ids_wnd = range(sum(wnd_size_lst[:i]), sum(wnd_size_lst[:i+1]), 1)\n",
    "        test_ids_candidate = random.sample(ids_wnd, test_num_wnd)\n",
    "        test_ids_wnd = read_test_data_ids(cur_cfg, i, test_ids_candidate)\n",
    "        if len(test_ids_wnd) != test_num_wnd:\n",
    "            print('test id number not matched!!!!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        temp_ids_wnd = set(ids_wnd) - set(test_ids_wnd)\n",
    "        train_ids_pos_wnd_total = set(temp_ids_wnd) & set(obj_ids)\n",
    "        real_pos_ratio = float(len(train_ids_pos_wnd_total)) / len(temp_ids_wnd)\n",
    "        if train_pos_ratio < real_pos_ratio:\n",
    "            train_ids_wnd = random.sample(temp_ids_wnd, train_num_wnd)\n",
    "        else:\n",
    "            pos_num_needed = int(train_num_wnd * train_pos_ratio)\n",
    "            pos_num_needed = min(\n",
    "                [\n",
    "                    pos_num_needed,\n",
    "                    # at least 30 frames\n",
    "                    int(real_pos_ratio * train_num_wnd * 30),\n",
    "                    len(train_ids_pos_wnd_total) // 2\n",
    "                ])\n",
    "            train_ids_pos_wnd = random.sample(\n",
    "                train_ids_pos_wnd_total, pos_num_needed)\n",
    "            train_ids_neg_wnd = random.sample(\n",
    "                temp_ids_wnd - train_ids_pos_wnd_total,\n",
    "                train_num_wnd - pos_num_needed)\n",
    "            train_ids_wnd = train_ids_pos_wnd + train_ids_neg_wnd\n",
    "            random.shuffle(train_ids_wnd)\n",
    "        train_ids += train_ids_wnd\n",
    "        test_ids += test_ids_wnd\n",
    "\n",
    "    X_train = get_frames_from_images(\n",
    "        train_ids, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop)\n",
    "    Y_train = get_labels(obj_ids, train_ids)\n",
    "    X_test = get_frames_from_images(\n",
    "        test_ids, img_sub_dirs, img_sub_nums, resol=max_resol, crop=crop)\n",
    "    Y_test = get_labels(obj_ids, test_ids)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_once(video_name, video_cfg):\n",
    "    # iterate input formats\n",
    "    video_clip_num = video_cfg['VIDEO_CLIP_NUM']\n",
    "    SMOOTH_WINDOW = FRAMES_PER_SEC * video_cfg['SMOOTH_SEC'] # for smooth the yolo output\n",
    "    input_cfgs = list(itertools.product(\n",
    "        video_cfg['train_num'],\n",
    "        video_cfg['test_num'],\n",
    "        video_cfg['wnd_num'],\n",
    "        video_cfg['train_pos_ratio'],\n",
    "        video_cfg['crop']\n",
    "    ))\n",
    "    print(f\"input_cfgs: {input_cfgs}\")\n",
    "    print()\n",
    "    \n",
    "    sub_videos = [video_name + '-' + str(p + 1) + '_10FPS' for p in range(video_clip_num)]\n",
    "    print(f\"sub_videos: {sub_videos}\")\n",
    "    print()\n",
    "    \n",
    "    img_sub_dirs = [os.path.join(JPG_ROOT_PATH, v) for v in sub_videos]\n",
    "    print(f\"img_sub_dirs: {img_sub_dirs}\")\n",
    "    print()\n",
    "    \n",
    "    img_sub_nums = [len(os.listdir(d)) for d in img_sub_dirs]\n",
    "    print(f\"img_sub_nums: {img_sub_nums}\")\n",
    "    print()\n",
    "    \n",
    "    total_frame_num = sum(img_sub_nums)\n",
    "    \n",
    "    csv_sub_files = [os.path.join(CSV_ROOT_PATH, d + '.csv') for d in sub_videos]\n",
    "    print(f\"csv_sub_files {csv_sub_files}\")\n",
    "    print()\n",
    "    \n",
    "    cur_cfg = {'video': video_name, 'smooth_window': SMOOTH_WINDOW}\n",
    "    for OBJECT in video_cfg['OBJECT']:\n",
    "        cur_cfg['OBJECT'] = OBJECT\n",
    "        \n",
    "        for input_cfg in input_cfgs:\n",
    "            cur_cfg['input_cfg'] = input_cfg\n",
    "            \n",
    "            \n",
    "            obj_ids, _ = get_csv_samples_many(\n",
    "                csv_sub_files, img_sub_nums, OBJECT, total_frame_num,\n",
    "                WINDOW=SMOOTH_WINDOW, crop=str2ilst(input_cfg[4]))\n",
    "\n",
    "            # a list of integers indicate available sizes / resolution of vide frames\n",
    "            resol_lst = [str2ilst(r) for r in video_cfg['resol']]\n",
    "\n",
    "            # FIXME better way to to find this number\n",
    "            max_resol = (max([r[0] for r in resol_lst]), max([r[1] for r in resol_lst]))\n",
    "            \n",
    "            X_train, Y_train, X_test, Y_test = read_input(\n",
    "                obj_ids, input_cfg, img_sub_nums, img_sub_dirs,\n",
    "                img_sub_nums, cur_cfg, max_resol=max_resol)\n",
    "            \n",
    "            for resol in resol_lst:\n",
    "                cur_cfg['resol'] = resol\n",
    "                if resol[0] != max_resol[0] or resol[1] != max_resol[1]:\n",
    "                    resized_X_train = resize_images(X_train, resol, dtype='float32')\n",
    "                    resized_X_test = resize_images(X_test, resol, dtype='float32')\n",
    "                else:\n",
    "                    resized_X_train = X_train\n",
    "                    resized_X_test = X_test\n",
    "                run_models(resized_X_train, Y_train, resized_X_test, Y_test, video_cfg, cur_cfg)\n",
    "                resized_X_train = None\n",
    "                resized_X_test = None\n",
    "                gc.collect()\n",
    "            \n",
    "            X_train = None\n",
    "            X_test = None\n",
    "            Y_train = None\n",
    "            Y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_cfgs: [(24000, 16000, 8, -1, '420,780,720,1280')]\n",
      "\n",
      "sub_videos: ['venice-canal-1_10FPS', 'venice-canal-2_10FPS', 'venice-canal-3_10FPS', 'venice-canal-4_10FPS', 'venice-canal-5_10FPS', 'venice-canal-6_10FPS', 'venice-canal-7_10FPS', 'venice-canal-8_10FPS']\n",
      "\n",
      "img_sub_dirs: ['/media/YOLO-RES-720P/jpg/venice-canal-1_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-2_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-3_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-4_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-5_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-6_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-7_10FPS', '/media/YOLO-RES-720P/jpg/venice-canal-8_10FPS']\n",
      "\n",
      "img_sub_nums: [216233, 215774, 216102, 216012, 215863, 216052, 216003, 216150]\n",
      "\n",
      "csv_sub_files ['/media/YOLO-RES-720P/out/venice-canal-1_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-2_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-3_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-4_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-5_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-6_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-7_10FPS.csv', '/media/YOLO-RES-720P/out/venice-canal-8_10FPS.csv']\n",
      "\n",
      "reading csv files from /media/YOLO-RES-720P/out/venice-canal-1_10FPS.csv...\n",
      "pos samples before/after smooth: 290333/227406\n",
      "reading input for config: (24000, 16000, 8, -1, '420,780,720,1280')\n",
      "reading label sum: 24000, pos 3129\n",
      "reading label sum: 16000, pos 2143\n",
      "running cfg: 16,8,1\n",
      "skip...\n",
      "running cfg: 32,16,1\n",
      "skip...\n",
      "running cfg: 64,32,1\n",
      "skip...\n",
      "running cfg: 16,8,2\n",
      "skip...\n",
      "running cfg: 32,16,2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1107 18:42:53.125545 140599609812800 training.py:706] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Training---------------------------------\n",
      "training samples: 3129/24000\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1107 18:42:53.632467 140599609812800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:466: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 5s 223us/sample - loss: 0.3540 - accuracy: 0.8682 - mean_squared_error: 0.1062\n",
      "Epoch 2/20\n",
      "24000/24000 [==============================] - 3s 110us/sample - loss: 0.2990 - accuracy: 0.8696 - mean_squared_error: 0.0905\n",
      "Epoch 3/20\n",
      "24000/24000 [==============================] - 3s 114us/sample - loss: 0.2824 - accuracy: 0.8725 - mean_squared_error: 0.0847\n",
      "Epoch 4/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2692 - accuracy: 0.8838 - mean_squared_error: 0.0794\n",
      "Epoch 5/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2582 - accuracy: 0.8875 - mean_squared_error: 0.0764\n",
      "Epoch 6/20\n",
      "24000/24000 [==============================] - 3s 112us/sample - loss: 0.2567 - accuracy: 0.8923 - mean_squared_error: 0.0754\n",
      "Epoch 7/20\n",
      "24000/24000 [==============================] - 3s 105us/sample - loss: 0.2499 - accuracy: 0.9011 - mean_squared_error: 0.0730\n",
      "Epoch 8/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2421 - accuracy: 0.9032 - mean_squared_error: 0.0710\n",
      "Epoch 9/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2390 - accuracy: 0.9053 - mean_squared_error: 0.0700\n",
      "Epoch 10/20\n",
      "24000/24000 [==============================] - 3s 109us/sample - loss: 0.2394 - accuracy: 0.9055 - mean_squared_error: 0.0699\n",
      "Epoch 11/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2342 - accuracy: 0.9062 - mean_squared_error: 0.0686\n",
      "Epoch 12/20\n",
      "24000/24000 [==============================] - 3s 105us/sample - loss: 0.2361 - accuracy: 0.9058 - mean_squared_error: 0.0692\n",
      "Epoch 13/20\n",
      "24000/24000 [==============================] - 3s 112us/sample - loss: 0.2319 - accuracy: 0.9070 - mean_squared_error: 0.0683\n",
      "Epoch 14/20\n",
      "24000/24000 [==============================] - 3s 106us/sample - loss: 0.2298 - accuracy: 0.9096 - mean_squared_error: 0.0669\n",
      "Epoch 15/20\n",
      "24000/24000 [==============================] - 3s 107us/sample - loss: 0.2280 - accuracy: 0.9093 - mean_squared_error: 0.0666\n",
      "Epoch 16/20\n",
      "24000/24000 [==============================] - 3s 111us/sample - loss: 0.2262 - accuracy: 0.9100 - mean_squared_error: 0.0660\n",
      "Epoch 17/20\n",
      "24000/24000 [==============================] - 3s 115us/sample - loss: 0.2239 - accuracy: 0.9119 - mean_squared_error: 0.0653\n",
      "Epoch 18/20\n",
      "24000/24000 [==============================] - 3s 105us/sample - loss: 0.2218 - accuracy: 0.9124 - mean_squared_error: 0.0647\n",
      "Epoch 19/20\n",
      "24000/24000 [==============================] - 3s 108us/sample - loss: 0.2253 - accuracy: 0.9112 - mean_squared_error: 0.0660\n",
      "Epoch 20/20\n",
      "24000/24000 [==============================] - 3s 108us/sample - loss: 0.2195 - accuracy: 0.9128 - mean_squared_error: 0.0640\n",
      "time diff 54.875351428985596\n",
      "----------------------Training done---------------------------------\n",
      "test num: 16000, pos num: 2143\n",
      "VARIABLE_STORAGE\n",
      "[[0.01781083 0.        ]\n",
      " [0.01925912 0.        ]\n",
      " [0.01634481 0.        ]\n",
      " ...\n",
      " [0.6253599  0.        ]\n",
      " [0.03638764 0.        ]\n",
      " [0.3878216  1.        ]]\n",
      "out_file: /media/YOLO-RES-720P/exp/venice-canal/venice-canal.json\n",
      "get_score_fname(cur_cfg): /media/YOLO-RES-720P/exp/venice-canal/scores/c8ddbe7a2c2daeda1f54d78ef43585ba\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "STOP HERE, debug",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b2bce33c76d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrun_video\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mrun_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-aa7e84774d43>\u001b[0m in \u001b[0;36mrun_once\u001b[0;34m(video_name, video_cfg)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mresized_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mresized_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mresized_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mresized_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4ac1781e2e19>\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(X_train, Y_train, X_test, Y_test, video_cfg, cur_cfg)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'out_file: {out_file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'get_score_fname(cur_cfg): {get_score_fname(cur_cfg)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STOP HERE, debug\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0madd_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: STOP HERE, debug"
     ]
    }
   ],
   "source": [
    "# automate experiments\n",
    "# with open('exp_params.cfg') as f:\n",
    "#     cfg = json.load(f)\n",
    "\n",
    "cfg = {\n",
    "    \"venice-canal\": {\n",
    "        \"VIDEO_CLIP_NUM\": 8,\n",
    "        \"train_num\": [\n",
    "            24000\n",
    "        ],\n",
    "        \"test_num\": [\n",
    "            16000\n",
    "        ],\n",
    "        \"wnd_num\": [\n",
    "            8\n",
    "        ],\n",
    "        \"OBJECT\": [\n",
    "            \"person\"\n",
    "        ],\n",
    "        \"resol\": [\n",
    "            \"25,25\",\n",
    "            \"50,50\",\n",
    "            \"100,100\"\n",
    "        ],\n",
    "        \"crop\": [\n",
    "            \"420,780,720,1280\"\n",
    "        ],\n",
    "        \"train_pos_ratio\": [\n",
    "            -1\n",
    "        ],\n",
    "        \"SMOOTH_SEC\": 3,\n",
    "        \"model\": [\n",
    "            \"16,8\",\n",
    "            \"32,16\",\n",
    "            \"64,32\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# FIXME modify the place to store output\n",
    "run_video = 'venice-canal'\n",
    "CUR_RES_ROOT_PATH = os.path.join(RES_ROOT_PATH, run_video)\n",
    "\n",
    "if not os.path.exists(CUR_RES_ROOT_PATH):\n",
    "    \n",
    "    raise Exception(f\"{CUR_RES_ROOT_PATH} does not exit\")\n",
    "\n",
    "for video in cfg.keys():\n",
    "    if video != run_video: \n",
    "        continue\n",
    "    run_once(video, cfg[video])\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training operator\n",
    "\n",
    "1. Configuration (some parameters)\n",
    "2. CSV file that contains information at which frame what objects were detected.\n",
    "3. specify epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100,100,-1,-1,-1,-1.npy     25,50,-1,-1,-1,-1.npy     50,50,-1,-1,-1,-1.npy\r\n",
      "100,100,200,0,720,1280.npy  25,50,200,0,720,1280.npy  50,50,200,0,720,1280.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls /media/YOLO-RES-720P/exp/jackson/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is equal [[ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " ...\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
